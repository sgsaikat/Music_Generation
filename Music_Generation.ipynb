{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HC7i15lYn-6i",
    "outputId": "17485905-7b80-49f9-ff5b-e4f3f44030b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "uFGr5H1eoCJI",
    "outputId": "22670ec5-d76c-4503-cba3-364cb9acab70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data   model.py   __pycache__  Solution.ipynb\tVisualization.ipynb\n",
      "logs   model.pyc  README.md    train.py\n",
      "model  output\t  sample.py    Untitled0.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls \"/content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J6NsSgUEn612",
    "outputId": "f00319e4-42f7-4a19-da9d-c541bbb6397c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation, Embedding, TimeDistributed, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "hzZoFi8Jn617",
    "outputId": "5317a8ed-3f1c-407b-a2ec-6f3627d4afba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/data \n",
      " /content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/data/Christmas_input.txt \n",
      " /content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/model\n"
     ]
    }
   ],
   "source": [
    "DIR = \"/content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/\"\n",
    "DATA_DIR = os.path.join(DIR, 'data')\n",
    "INPUT_FILE = os.path.join(DATA_DIR, 'Christmas_input.txt')\n",
    "MODEL_DIR = os.path.join(DIR, 'model')\n",
    "\n",
    "print(DATA_DIR, \"\\n\", INPUT_FILE, \"\\n\", MODEL_DIR)\n",
    "\n",
    "BATCHES = 16\n",
    "SEQ_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYVDcjFin61-"
   },
   "source": [
    "## Logic: \n",
    "> Divide the entire data into chunks (batches), then at each iteration generate a batch of data such that for every batch select the sequence_length # of chars.\n",
    "\n",
    "__Corpus:__ \"Quick Brown Fox jumped over the lazy dog\"<br>\n",
    "length = 40; batches = 4; sequence_length = 5; batch_chars = 10;<br>\n",
    "\n",
    "<font color=green>__Batch Chars:__</font><br>\n",
    "Quick Brow<br>\n",
    "n Fox jump<br>\n",
    "ed over th<br>\n",
    "e lazy dog<br>\n",
    "\n",
    "<font color=green>__Batch_Seq-1 data:__</font><br>\n",
    "Quick<br>\n",
    "n Fox<br>\n",
    "ed ov<br>\n",
    "e laz<br>\n",
    "\n",
    "<font color=green>__Batch_Seq-2 data:__</font><br>\n",
    " Brow<br>\n",
    " jump<br>\n",
    "er th<br>\n",
    "y dog<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWkA4ghNn61_"
   },
   "outputs": [],
   "source": [
    "def read_batches(data, vocab_size):\n",
    "    '''Generator Function to generate data in batches.'''\n",
    "    data_len = len(data)    # This is the Total # of characters in the corpus\n",
    "    batch_chars = int(data_len / BATCHES)    # This denotes the max # of characters present in each batch\n",
    "    \n",
    "    # Sequence_length denotes the # of chars to be fed to the ML model (Input --> # rows = batches, #cols = sequence_length)\n",
    "    # Following loop will run for all the chars in the corpus with a step of sequence_length\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH):\n",
    "        X = np.zeros((BATCHES, SEQ_LENGTH))    # This will initialize a np_array with zeros of size [16x64]\n",
    "        Y = np.zeros((BATCHES, SEQ_LENGTH, vocab_size))    # This will initialize a np_array with zeros of size [16x64x86]\n",
    "        # Essentially Y holds the values of the next sequence character in one-hot encoded form in the Corpus (Target Variable)\n",
    "        \n",
    "        # Following nested loop will run thru all the batches for every char in each sequence\n",
    "        for batch in range(BATCHES):\n",
    "            for i in range(SEQ_LENGTH):\n",
    "                X[batch, i] = data[batch * batch_chars + start + i]\n",
    "#                 try:\n",
    "                Y[batch, i, data[batch * batch_chars + start + i + 1]] = 1\n",
    "#                 except:\n",
    "#                     Y[batch, i, data[0]] = 1    # For the last character, the Target will point to the 1st character\n",
    "\n",
    "        yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeNRm-0Hn62C"
   },
   "outputs": [],
   "source": [
    "def get_model(batch_size, seq_len, vocab_size):\n",
    "#     model = Sequential()\n",
    "    input1 = Input(batch_shape=(batch_size, seq_len))\n",
    "    embeddings = Embedding(vocab_size, 512)(input1)\n",
    "    \n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(embeddings)\n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(lstm_out)\n",
    "    lstm_out = LSTM(512, return_sequences=True, activation='tanh')(lstm_out)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "    \n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(lstm_out)\n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(lstm_out)\n",
    "    lstm_out = LSTM(512, return_sequences=True, activation='tanh')(lstm_out)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "    \n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(lstm_out)\n",
    "    lstm_out, state_h, state_c = LSTM(512, return_sequences=True, return_state=True)(lstm_out)\n",
    "    lstm_out = LSTM(512, return_sequences=True, activation='tanh')(lstm_out)\n",
    "    lstm_out = Dropout(0.5)(lstm_out)\n",
    "    \n",
    "    output1 = TimeDistributed(Dense(vocab_size, activation='softmax'))(lstm_out)\n",
    "    model = Model(inputs=input1, outputs=output1)\n",
    "    \n",
    "#     model.add(Embedding(vocab_size, 512, batch_input_shape=(batch_size, seq_len)))\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         model.add(LSTM(256, return_sequences=(i != 2), return_state=True))\n",
    "#         model.add(LSTM(256, return_sequences=True, return_state=False))\n",
    "#         model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(256, return_sequences=True, return_state=True))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(256, return_sequences=True, return_state=True))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(LSTM(256))\n",
    "    \n",
    "#     model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "afnrdJ4Hn62E"
   },
   "outputs": [],
   "source": [
    "def save_weights(epoch, model):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    model.save_weights(os.path.join(MODEL_DIR, f'weights.{epoch}.h5'))\n",
    "    print(f\"Saved checkpoint to 'weights.{epoch}.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4771
    },
    "colab_type": "code",
    "id": "3AQZbT-Wn62H",
    "outputId": "a14a1cd8-2d1f-498a-a617-7788dabd23b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 73\n",
      "Total Characters in File-'/content/gdrive/My Drive/Colab Notebooks/Generate Music/char-rnn-keras-master.zip (Unzipped Files)/char-rnn-keras-master/data/Christmas_input.txt' ==> 3839\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (16, 128)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (16, 128, 512)            37376     \n",
      "_________________________________________________________________\n",
      "lstm_199 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_200 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_201 (LSTM)              (16, 128, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (16, 128, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_202 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_203 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_204 (LSTM)              (16, 128, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (16, 128, 512)            0         \n",
      "_________________________________________________________________\n",
      "lstm_205 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_206 (LSTM)              [(16, 128, 512), (16, 512 2099200   \n",
      "_________________________________________________________________\n",
      "lstm_207 (LSTM)              (16, 128, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (16, 128, 512)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (16, 128, 73)             37449     \n",
      "=================================================================\n",
      "Total params: 18,967,625\n",
      "Trainable params: 18,967,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch: 10 =====> Batch: 1, Loss: 3.6582727432250977, Accuracy: 0.09375\n",
      "Epoch: 20 =====> Batch: 1, Loss: 3.58113431930542, Accuracy: 0.126953125\n",
      "Epoch: 30 =====> Batch: 1, Loss: 3.5404701232910156, Accuracy: 0.13720703125\n",
      "Epoch: 40 =====> Batch: 1, Loss: 3.534634590148926, Accuracy: 0.142578125\n",
      "Epoch: 50 =====> Batch: 1, Loss: 3.3829708099365234, Accuracy: 0.1572265625\n",
      "Saved checkpoint to 'weights.50.h5'\n",
      "Epoch: 60 =====> Batch: 1, Loss: 3.285804271697998, Accuracy: 0.15771484375\n",
      "Epoch: 70 =====> Batch: 1, Loss: 3.197971820831299, Accuracy: 0.1669921875\n",
      "Epoch: 80 =====> Batch: 1, Loss: 3.1601943969726562, Accuracy: 0.16650390625\n",
      "Epoch: 90 =====> Batch: 1, Loss: 3.057746410369873, Accuracy: 0.18505859375\n",
      "Epoch: 100 =====> Batch: 1, Loss: 2.940140962600708, Accuracy: 0.20166015625\n",
      "Saved checkpoint to 'weights.100.h5'\n",
      "Epoch: 110 =====> Batch: 1, Loss: 2.84507417678833, Accuracy: 0.21875\n",
      "Epoch: 120 =====> Batch: 1, Loss: 2.784970760345459, Accuracy: 0.2158203125\n",
      "Epoch: 130 =====> Batch: 1, Loss: 2.7134621143341064, Accuracy: 0.2294921875\n",
      "Epoch: 140 =====> Batch: 1, Loss: 2.6094348430633545, Accuracy: 0.23583984375\n",
      "Epoch: 150 =====> Batch: 1, Loss: 2.458305835723877, Accuracy: 0.2626953125\n",
      "Saved checkpoint to 'weights.150.h5'\n",
      "Epoch: 160 =====> Batch: 1, Loss: 2.6443240642547607, Accuracy: 0.234375\n",
      "Epoch: 170 =====> Batch: 1, Loss: 2.2913155555725098, Accuracy: 0.2841796875\n",
      "Epoch: 180 =====> Batch: 1, Loss: 2.1279940605163574, Accuracy: 0.33203125\n",
      "Epoch: 190 =====> Batch: 1, Loss: 1.9792296886444092, Accuracy: 0.365234375\n",
      "Epoch: 200 =====> Batch: 1, Loss: 1.9868810176849365, Accuracy: 0.35009765625\n",
      "Saved checkpoint to 'weights.200.h5'\n",
      "Epoch: 210 =====> Batch: 1, Loss: 2.255448818206787, Accuracy: 0.29931640625\n",
      "Epoch: 220 =====> Batch: 1, Loss: 2.1652121543884277, Accuracy: 0.3212890625\n",
      "Epoch: 230 =====> Batch: 1, Loss: 1.867772102355957, Accuracy: 0.39404296875\n",
      "Epoch: 240 =====> Batch: 1, Loss: 1.6747468709945679, Accuracy: 0.4541015625\n",
      "Epoch: 250 =====> Batch: 1, Loss: 1.5773682594299316, Accuracy: 0.47412109375\n",
      "Saved checkpoint to 'weights.250.h5'\n",
      "Epoch: 260 =====> Batch: 1, Loss: 1.4439682960510254, Accuracy: 0.51611328125\n",
      "Epoch: 270 =====> Batch: 1, Loss: 1.329599380493164, Accuracy: 0.5400390625\n",
      "Epoch: 280 =====> Batch: 1, Loss: 1.2426884174346924, Accuracy: 0.5634765625\n",
      "Epoch: 290 =====> Batch: 1, Loss: 1.1473195552825928, Accuracy: 0.5927734375\n",
      "Epoch: 300 =====> Batch: 1, Loss: 1.04878568649292, Accuracy: 0.62548828125\n",
      "Saved checkpoint to 'weights.300.h5'\n",
      "Epoch: 310 =====> Batch: 1, Loss: 0.9587072730064392, Accuracy: 0.66162109375\n",
      "Epoch: 320 =====> Batch: 1, Loss: 0.8901175260543823, Accuracy: 0.68798828125\n",
      "Epoch: 330 =====> Batch: 1, Loss: 1.349217414855957, Accuracy: 0.5146484375\n",
      "Epoch: 340 =====> Batch: 1, Loss: 0.9516748189926147, Accuracy: 0.6552734375\n",
      "Epoch: 350 =====> Batch: 1, Loss: 0.8074253797531128, Accuracy: 0.71533203125\n",
      "Saved checkpoint to 'weights.350.h5'\n",
      "Epoch: 360 =====> Batch: 1, Loss: 0.6937963962554932, Accuracy: 0.76611328125\n",
      "Epoch: 370 =====> Batch: 1, Loss: 0.6225983500480652, Accuracy: 0.80224609375\n",
      "Epoch: 380 =====> Batch: 1, Loss: 0.5643259286880493, Accuracy: 0.81884765625\n",
      "Epoch: 390 =====> Batch: 1, Loss: 0.5277417898178101, Accuracy: 0.83740234375\n",
      "Epoch: 400 =====> Batch: 1, Loss: 0.4668791890144348, Accuracy: 0.86865234375\n",
      "Saved checkpoint to 'weights.400.h5'\n",
      "Epoch: 410 =====> Batch: 1, Loss: 0.4354012906551361, Accuracy: 0.87158203125\n",
      "Epoch: 420 =====> Batch: 1, Loss: 0.39181041717529297, Accuracy: 0.88818359375\n",
      "Epoch: 430 =====> Batch: 1, Loss: 0.37474608421325684, Accuracy: 0.892578125\n",
      "Epoch: 440 =====> Batch: 1, Loss: 0.3279570937156677, Accuracy: 0.91943359375\n",
      "Epoch: 450 =====> Batch: 1, Loss: 0.31392624974250793, Accuracy: 0.9208984375\n",
      "Saved checkpoint to 'weights.450.h5'\n",
      "Epoch: 460 =====> Batch: 1, Loss: 0.270550400018692, Accuracy: 0.93701171875\n",
      "Epoch: 470 =====> Batch: 1, Loss: 0.26597166061401367, Accuracy: 0.93798828125\n",
      "Epoch: 480 =====> Batch: 1, Loss: 0.2499593049287796, Accuracy: 0.93408203125\n",
      "Epoch: 490 =====> Batch: 1, Loss: 0.22781407833099365, Accuracy: 0.951171875\n",
      "Epoch: 500 =====> Batch: 1, Loss: 0.20051726698875427, Accuracy: 0.9580078125\n",
      "Saved checkpoint to 'weights.500.h5'\n",
      "Epoch: 510 =====> Batch: 1, Loss: 0.17960169911384583, Accuracy: 0.96533203125\n",
      "Epoch: 520 =====> Batch: 1, Loss: 0.17238622903823853, Accuracy: 0.96484375\n",
      "Epoch: 530 =====> Batch: 1, Loss: 0.15748998522758484, Accuracy: 0.96728515625\n",
      "Epoch: 540 =====> Batch: 1, Loss: 2.4169411659240723, Accuracy: 0.43408203125\n",
      "Epoch: 550 =====> Batch: 1, Loss: 2.1808979511260986, Accuracy: 0.3515625\n",
      "Saved checkpoint to 'weights.550.h5'\n",
      "Epoch: 560 =====> Batch: 1, Loss: 1.4349795579910278, Accuracy: 0.5087890625\n",
      "Epoch: 570 =====> Batch: 1, Loss: 0.9356045722961426, Accuracy: 0.689453125\n",
      "Epoch: 580 =====> Batch: 1, Loss: 0.6155048608779907, Accuracy: 0.8154296875\n",
      "Epoch: 590 =====> Batch: 1, Loss: 0.41168686747550964, Accuracy: 0.88818359375\n",
      "Epoch: 600 =====> Batch: 1, Loss: 0.30750489234924316, Accuracy: 0.92333984375\n",
      "Saved checkpoint to 'weights.600.h5'\n",
      "Epoch: 610 =====> Batch: 1, Loss: 0.23760901391506195, Accuracy: 0.951171875\n",
      "Epoch: 620 =====> Batch: 1, Loss: 0.20387984812259674, Accuracy: 0.9580078125\n",
      "Epoch: 630 =====> Batch: 1, Loss: 0.17586112022399902, Accuracy: 0.96435546875\n",
      "Epoch: 640 =====> Batch: 1, Loss: 0.15990164875984192, Accuracy: 0.96728515625\n",
      "Epoch: 650 =====> Batch: 1, Loss: 0.144492968916893, Accuracy: 0.97021484375\n",
      "Saved checkpoint to 'weights.650.h5'\n",
      "Epoch: 660 =====> Batch: 1, Loss: 0.1294635832309723, Accuracy: 0.97509765625\n",
      "Epoch: 670 =====> Batch: 1, Loss: 0.12128383666276932, Accuracy: 0.97900390625\n",
      "Epoch: 680 =====> Batch: 1, Loss: 0.11383775621652603, Accuracy: 0.978515625\n",
      "Epoch: 690 =====> Batch: 1, Loss: 0.10986144840717316, Accuracy: 0.9765625\n",
      "Epoch: 700 =====> Batch: 1, Loss: 0.1070161685347557, Accuracy: 0.97705078125\n",
      "Saved checkpoint to 'weights.700.h5'\n",
      "Epoch: 710 =====> Batch: 1, Loss: 0.09743617475032806, Accuracy: 0.97998046875\n",
      "Epoch: 720 =====> Batch: 1, Loss: 0.09593317657709122, Accuracy: 0.97900390625\n",
      "Epoch: 730 =====> Batch: 1, Loss: 0.09405076503753662, Accuracy: 0.9833984375\n",
      "Epoch: 740 =====> Batch: 1, Loss: 0.0884915441274643, Accuracy: 0.98291015625\n",
      "Epoch: 750 =====> Batch: 1, Loss: 0.08253386616706848, Accuracy: 0.9833984375\n",
      "Saved checkpoint to 'weights.750.h5'\n",
      "Epoch: 760 =====> Batch: 1, Loss: 0.08752655237913132, Accuracy: 0.9814453125\n",
      "Epoch: 770 =====> Batch: 1, Loss: 0.07936875522136688, Accuracy: 0.984375\n",
      "Epoch: 780 =====> Batch: 1, Loss: 0.07951995730400085, Accuracy: 0.98388671875\n",
      "Epoch: 790 =====> Batch: 1, Loss: 0.0748923048377037, Accuracy: 0.98486328125\n",
      "Epoch: 800 =====> Batch: 1, Loss: 0.07413260638713837, Accuracy: 0.9853515625\n",
      "Saved checkpoint to 'weights.800.h5'\n",
      "Epoch: 810 =====> Batch: 1, Loss: 0.07450158894062042, Accuracy: 0.98388671875\n",
      "Epoch: 820 =====> Batch: 1, Loss: 0.07092299312353134, Accuracy: 0.98291015625\n",
      "Epoch: 830 =====> Batch: 1, Loss: 0.06836964190006256, Accuracy: 0.986328125\n",
      "Epoch: 840 =====> Batch: 1, Loss: 0.06975563615560532, Accuracy: 0.98486328125\n",
      "Epoch: 850 =====> Batch: 1, Loss: 0.06506872177124023, Accuracy: 0.98681640625\n",
      "Saved checkpoint to 'weights.850.h5'\n",
      "Epoch: 860 =====> Batch: 1, Loss: 0.0629449337720871, Accuracy: 0.9853515625\n",
      "Epoch: 870 =====> Batch: 1, Loss: 0.06327186524868011, Accuracy: 0.98681640625\n",
      "Epoch: 880 =====> Batch: 1, Loss: 0.062345437705516815, Accuracy: 0.98583984375\n",
      "Epoch: 890 =====> Batch: 1, Loss: 0.07956916093826294, Accuracy: 0.98193359375\n",
      "Epoch: 900 =====> Batch: 1, Loss: 0.06441754102706909, Accuracy: 0.986328125\n",
      "Saved checkpoint to 'weights.900.h5'\n",
      "Epoch: 910 =====> Batch: 1, Loss: 0.06785550713539124, Accuracy: 0.98291015625\n",
      "Epoch: 920 =====> Batch: 1, Loss: 0.05923410877585411, Accuracy: 0.9873046875\n",
      "Epoch: 930 =====> Batch: 1, Loss: 0.05604827404022217, Accuracy: 0.98681640625\n",
      "Epoch: 940 =====> Batch: 1, Loss: 0.054580267518758774, Accuracy: 0.98876953125\n",
      "Epoch: 950 =====> Batch: 1, Loss: 0.053555238991975784, Accuracy: 0.98681640625\n",
      "Saved checkpoint to 'weights.950.h5'\n",
      "Epoch: 960 =====> Batch: 1, Loss: 0.05083739012479782, Accuracy: 0.98779296875\n",
      "Epoch: 970 =====> Batch: 1, Loss: 0.04931800812482834, Accuracy: 0.98828125\n",
      "Epoch: 980 =====> Batch: 1, Loss: 0.049096640199422836, Accuracy: 0.9892578125\n",
      "Epoch: 990 =====> Batch: 1, Loss: 0.0502888560295105, Accuracy: 0.98779296875\n",
      "Epoch: 1000 =====> Batch: 1, Loss: 0.047218114137649536, Accuracy: 0.98876953125\n",
      "Saved checkpoint to 'weights.1000.h5'\n",
      "Epoch: 1010 =====> Batch: 1, Loss: 0.04625425487756729, Accuracy: 0.99072265625\n",
      "Epoch: 1020 =====> Batch: 1, Loss: 0.04832674562931061, Accuracy: 0.98828125\n",
      "Epoch: 1030 =====> Batch: 1, Loss: 0.04603872448205948, Accuracy: 0.9873046875\n",
      "Epoch: 1040 =====> Batch: 1, Loss: 0.0444469153881073, Accuracy: 0.990234375\n",
      "Epoch: 1050 =====> Batch: 1, Loss: 0.042371928691864014, Accuracy: 0.9912109375\n",
      "Saved checkpoint to 'weights.1050.h5'\n",
      "Epoch: 1060 =====> Batch: 1, Loss: 0.044310398399829865, Accuracy: 0.990234375\n",
      "Epoch: 1070 =====> Batch: 1, Loss: 0.03990578651428223, Accuracy: 0.9912109375\n",
      "Epoch: 1080 =====> Batch: 1, Loss: 0.041226763278245926, Accuracy: 0.990234375\n",
      "Epoch: 1090 =====> Batch: 1, Loss: 0.03949457406997681, Accuracy: 0.99072265625\n",
      "Epoch: 1100 =====> Batch: 1, Loss: 0.03923606127500534, Accuracy: 0.990234375\n",
      "Saved checkpoint to 'weights.1100.h5'\n",
      "Epoch: 1110 =====> Batch: 1, Loss: 0.03922009468078613, Accuracy: 0.990234375\n",
      "Epoch: 1120 =====> Batch: 1, Loss: 0.039824966341257095, Accuracy: 0.98974609375\n",
      "Epoch: 1130 =====> Batch: 1, Loss: 0.03767046704888344, Accuracy: 0.9892578125\n",
      "Epoch: 1140 =====> Batch: 1, Loss: 0.0366797000169754, Accuracy: 0.99072265625\n",
      "Epoch: 1150 =====> Batch: 1, Loss: 0.03724193572998047, Accuracy: 0.9912109375\n",
      "Saved checkpoint to 'weights.1150.h5'\n",
      "Epoch: 1160 =====> Batch: 1, Loss: 0.034381963312625885, Accuracy: 0.99169921875\n",
      "Epoch: 1170 =====> Batch: 1, Loss: 0.03647494316101074, Accuracy: 0.9892578125\n",
      "Epoch: 1180 =====> Batch: 1, Loss: 0.035275112837553024, Accuracy: 0.98974609375\n",
      "Epoch: 1190 =====> Batch: 1, Loss: 0.034871138632297516, Accuracy: 0.99072265625\n",
      "Epoch: 1200 =====> Batch: 1, Loss: 0.035638000816106796, Accuracy: 0.98974609375\n",
      "Saved checkpoint to 'weights.1200.h5'\n",
      "Epoch: 1210 =====> Batch: 1, Loss: 0.0319085493683815, Accuracy: 0.9912109375\n",
      "Epoch: 1220 =====> Batch: 1, Loss: 0.0337444543838501, Accuracy: 0.9931640625\n",
      "Epoch: 1230 =====> Batch: 1, Loss: 0.031860727816820145, Accuracy: 0.99267578125\n",
      "Epoch: 1240 =====> Batch: 1, Loss: 0.03228289633989334, Accuracy: 0.98974609375\n",
      "Epoch: 1250 =====> Batch: 1, Loss: 0.03124295361340046, Accuracy: 0.99169921875\n",
      "Saved checkpoint to 'weights.1250.h5'\n",
      "Epoch: 1260 =====> Batch: 1, Loss: 0.031019477173686028, Accuracy: 0.9912109375\n",
      "Epoch: 1270 =====> Batch: 1, Loss: 0.03185034543275833, Accuracy: 0.990234375\n",
      "Epoch: 1280 =====> Batch: 1, Loss: 0.031345635652542114, Accuracy: 0.9912109375\n",
      "Epoch: 1290 =====> Batch: 1, Loss: 0.030082914978265762, Accuracy: 0.99267578125\n",
      "Epoch: 1300 =====> Batch: 1, Loss: 0.027833236381411552, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1300.h5'\n",
      "Epoch: 1310 =====> Batch: 1, Loss: 0.03021678328514099, Accuracy: 0.99169921875\n",
      "Epoch: 1320 =====> Batch: 1, Loss: 0.027934152632951736, Accuracy: 0.99169921875\n",
      "Epoch: 1330 =====> Batch: 1, Loss: 0.03180805593729019, Accuracy: 0.9892578125\n",
      "Epoch: 1340 =====> Batch: 1, Loss: 0.02799353376030922, Accuracy: 0.9931640625\n",
      "Epoch: 1350 =====> Batch: 1, Loss: 0.025651946663856506, Accuracy: 0.9921875\n",
      "Saved checkpoint to 'weights.1350.h5'\n",
      "Epoch: 1360 =====> Batch: 1, Loss: 0.02777702361345291, Accuracy: 0.9921875\n",
      "Epoch: 1370 =====> Batch: 1, Loss: 0.028151050209999084, Accuracy: 0.9912109375\n",
      "Epoch: 1380 =====> Batch: 1, Loss: 0.02652355097234249, Accuracy: 0.9921875\n",
      "Epoch: 1390 =====> Batch: 1, Loss: 0.026473350822925568, Accuracy: 0.99169921875\n",
      "Epoch: 1400 =====> Batch: 1, Loss: 0.025828657671809196, Accuracy: 0.9931640625\n",
      "Saved checkpoint to 'weights.1400.h5'\n",
      "Epoch: 1410 =====> Batch: 1, Loss: 0.026374105364084244, Accuracy: 0.9912109375\n",
      "Epoch: 1420 =====> Batch: 1, Loss: 0.024547817185521126, Accuracy: 0.99267578125\n",
      "Epoch: 1430 =====> Batch: 1, Loss: 0.02341262251138687, Accuracy: 0.99365234375\n",
      "Epoch: 1440 =====> Batch: 1, Loss: 0.024960888549685478, Accuracy: 0.9931640625\n",
      "Epoch: 1450 =====> Batch: 1, Loss: 0.021136481314897537, Accuracy: 0.99462890625\n",
      "Saved checkpoint to 'weights.1450.h5'\n",
      "Epoch: 1460 =====> Batch: 1, Loss: 0.02320185676217079, Accuracy: 0.9931640625\n",
      "Epoch: 1470 =====> Batch: 1, Loss: 0.022804342210292816, Accuracy: 0.99267578125\n",
      "Epoch: 1480 =====> Batch: 1, Loss: 0.023280078545212746, Accuracy: 0.99267578125\n",
      "Epoch: 1490 =====> Batch: 1, Loss: 0.0223133135586977, Accuracy: 0.9931640625\n",
      "Epoch: 1500 =====> Batch: 1, Loss: 0.022181354463100433, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1500.h5'\n",
      "Epoch: 1510 =====> Batch: 1, Loss: 0.02237766608595848, Accuracy: 0.994140625\n",
      "Epoch: 1520 =====> Batch: 1, Loss: 0.021980175748467445, Accuracy: 0.99365234375\n",
      "Epoch: 1530 =====> Batch: 1, Loss: 0.021122999489307404, Accuracy: 0.99365234375\n",
      "Epoch: 1540 =====> Batch: 1, Loss: 0.021026767790317535, Accuracy: 0.99365234375\n",
      "Epoch: 1550 =====> Batch: 1, Loss: 0.020787212997674942, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1550.h5'\n",
      "Epoch: 1560 =====> Batch: 1, Loss: 0.020935144275426865, Accuracy: 0.99365234375\n",
      "Epoch: 1570 =====> Batch: 1, Loss: 0.020346026867628098, Accuracy: 0.99560546875\n",
      "Epoch: 1580 =====> Batch: 1, Loss: 0.02054583840072155, Accuracy: 0.9931640625\n",
      "Epoch: 1590 =====> Batch: 1, Loss: 0.018559914082288742, Accuracy: 0.994140625\n",
      "Epoch: 1600 =====> Batch: 1, Loss: 0.01889720931649208, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1600.h5'\n",
      "Epoch: 1610 =====> Batch: 1, Loss: 0.019249768927693367, Accuracy: 0.99365234375\n",
      "Epoch: 1620 =====> Batch: 1, Loss: 0.01927432417869568, Accuracy: 0.994140625\n",
      "Epoch: 1630 =====> Batch: 1, Loss: 0.018066290766000748, Accuracy: 0.994140625\n",
      "Epoch: 1640 =====> Batch: 1, Loss: 0.019308794289827347, Accuracy: 0.994140625\n",
      "Epoch: 1650 =====> Batch: 1, Loss: 0.018940791487693787, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1650.h5'\n",
      "Epoch: 1660 =====> Batch: 1, Loss: 0.017469383776187897, Accuracy: 0.99365234375\n",
      "Epoch: 1670 =====> Batch: 1, Loss: 0.01985570788383484, Accuracy: 0.99365234375\n",
      "Epoch: 1680 =====> Batch: 1, Loss: 0.017913177609443665, Accuracy: 0.99462890625\n",
      "Epoch: 1690 =====> Batch: 1, Loss: 0.017944592982530594, Accuracy: 0.994140625\n",
      "Epoch: 1700 =====> Batch: 1, Loss: 0.01934850960969925, Accuracy: 0.99365234375\n",
      "Saved checkpoint to 'weights.1700.h5'\n",
      "Epoch: 1710 =====> Batch: 1, Loss: 0.016813240945339203, Accuracy: 0.9951171875\n",
      "Epoch: 1720 =====> Batch: 1, Loss: 0.01817764714360237, Accuracy: 0.99462890625\n",
      "Epoch: 1730 =====> Batch: 1, Loss: 0.01844014599919319, Accuracy: 0.99365234375\n",
      "Epoch: 1740 =====> Batch: 1, Loss: 0.018054869025945663, Accuracy: 0.994140625\n",
      "Epoch: 1750 =====> Batch: 1, Loss: 0.01748201623558998, Accuracy: 0.99462890625\n",
      "Saved checkpoint to 'weights.1750.h5'\n",
      "Epoch: 1760 =====> Batch: 1, Loss: 0.017850413918495178, Accuracy: 0.99365234375\n",
      "Epoch: 1770 =====> Batch: 1, Loss: 0.01752801239490509, Accuracy: 0.99462890625\n",
      "Epoch: 1780 =====> Batch: 1, Loss: 0.017333608120679855, Accuracy: 0.99462890625\n",
      "Epoch: 1790 =====> Batch: 1, Loss: 0.015932776033878326, Accuracy: 0.994140625\n",
      "Epoch: 1800 =====> Batch: 1, Loss: 0.01618969440460205, Accuracy: 0.99462890625\n",
      "Saved checkpoint to 'weights.1800.h5'\n",
      "Epoch: 1810 =====> Batch: 1, Loss: 0.01698995567858219, Accuracy: 0.99365234375\n",
      "Epoch: 1820 =====> Batch: 1, Loss: 0.01646682620048523, Accuracy: 0.99365234375\n",
      "Epoch: 1830 =====> Batch: 1, Loss: 0.01543209608644247, Accuracy: 0.99462890625\n",
      "Epoch: 1840 =====> Batch: 1, Loss: 0.018478890880942345, Accuracy: 0.99365234375\n",
      "Epoch: 1850 =====> Batch: 1, Loss: 0.0162469781935215, Accuracy: 0.994140625\n",
      "Saved checkpoint to 'weights.1850.h5'\n",
      "Epoch: 1860 =====> Batch: 1, Loss: 0.015123745426535606, Accuracy: 0.99560546875\n",
      "Epoch: 1870 =====> Batch: 1, Loss: 0.01587691530585289, Accuracy: 0.99365234375\n",
      "Epoch: 1880 =====> Batch: 1, Loss: 0.015106831677258015, Accuracy: 0.994140625\n",
      "Epoch: 1890 =====> Batch: 1, Loss: 0.01733747310936451, Accuracy: 0.994140625\n",
      "Epoch: 1900 =====> Batch: 1, Loss: 0.017300648614764214, Accuracy: 0.994140625\n",
      "Saved checkpoint to 'weights.1900.h5'\n",
      "Epoch: 1910 =====> Batch: 1, Loss: 0.014176287688314915, Accuracy: 0.9951171875\n",
      "Epoch: 1920 =====> Batch: 1, Loss: 0.014892306178808212, Accuracy: 0.99462890625\n",
      "Epoch: 1930 =====> Batch: 1, Loss: 0.012965243309736252, Accuracy: 0.9951171875\n",
      "Epoch: 1940 =====> Batch: 1, Loss: 0.013266870751976967, Accuracy: 0.99462890625\n",
      "Epoch: 1950 =====> Batch: 1, Loss: 0.0180938933044672, Accuracy: 0.99462890625\n",
      "Saved checkpoint to 'weights.1950.h5'\n",
      "Epoch: 1960 =====> Batch: 1, Loss: 5.436473369598389, Accuracy: 0.04736328125\n",
      "Epoch: 1970 =====> Batch: 1, Loss: 3.5238208770751953, Accuracy: 0.13427734375\n",
      "Epoch: 1980 =====> Batch: 1, Loss: 3.46620512008667, Accuracy: 0.146484375\n",
      "Epoch: 1990 =====> Batch: 1, Loss: 3.408687114715576, Accuracy: 0.15087890625\n",
      "Epoch: 2000 =====> Batch: 1, Loss: 3.405200242996216, Accuracy: 0.14306640625\n",
      "Saved checkpoint to 'weights.2000.h5'\n",
      "Saved checkpoint to 'weights.final.h5'\n",
      "CPU times: user 1h 2min 27s, sys: 3min 56s, total: 1h 6min 23s\n",
      "Wall time: 46min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train_data(text, epochs=2000, save_freq=50):\n",
    "    char_to_idx = { ch: i for (i, ch) in enumerate(sorted(set(text))) }\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'char_to_idx.json'), 'w') as file:\n",
    "        json.dump(char_to_idx, file)\n",
    "    \n",
    "    vocab_size = len(char_to_idx)\n",
    "    print(f\"Number of unique characters: {vocab_size}\")\n",
    "\n",
    "    indexed_data = np.array([char_to_idx[i] for i in text], dtype=np.int32)\n",
    "    print(f\"Total Characters in File-'{INPUT_FILE}' ==> {indexed_data.size}\")\n",
    "\n",
    "    with open('progress.csv', 'w') as file:\n",
    "        file.write(\"epoch,loss,accuracy\\n\")\n",
    "\n",
    "    model = get_model(BATCHES, SEQ_LENGTH, vocab_size)\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    if os.path.exists(os.path.join(MODEL_DIR, 'weights.final.h5')):\n",
    "        model.load_weights(os.path.join(MODEL_DIR, 'weights.final.h5'))\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        losses, accs = [], []\n",
    "        for i, (x, y) in enumerate(read_batches(indexed_data, vocab_size), start=1):\n",
    "            loss, acc = model.train_on_batch(x, y)\n",
    "#             print(\"I AM HERE ===>\", i)\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch: {epoch} =====> Batch: {i}, Loss: {loss}, Accuracy: {acc}\")\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "                print(f\"Epoch: {epoch} =====> Batch: {i}, Loss: {loss}, Accuracy: {acc}\")\n",
    "\n",
    "        with open('progress.csv', 'a') as file:\n",
    "            file.write(f\"{epoch},{np.average(losses)},{np.average(accs)}\\n\")\n",
    "        \n",
    "        if epoch % save_freq == 0:\n",
    "            save_weights(epoch, model)\n",
    "    \n",
    "    with open(os.path.join(MODEL_DIR, 'model.json'), 'w') as file:\n",
    "        file.write(model.to_json())\n",
    "    save_weights(\"final\", model)\n",
    "\n",
    "text = open(os.path.join(DATA_DIR, INPUT_FILE)).read()\n",
    "train_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "colab_type": "code",
    "id": "AOhqIii3n62M",
    "outputId": "fc514390-771c-4ab6-dfc4-661d8d742c33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XA7G\"m \"g\"XmmmF\"| m\" \n",
      "XAa \":  \"m\"G X\"ABm  \"D\"A \"\" ASn |  n\" gmA\"mmm\"nnCA\"\" |G XA%N\" G   mAD\" m\" n\"\"|X\" |\"\"m\"| \"NCXgXNAX mG\"\" \"mX \"\"\"NgGm\"NXXX\n",
      "|A\" \"\"%n\"\"BG\" \n",
      "N\"X m\"N:|M|N  mi\n",
      "nX\"\"\"\n",
      "\"ng NDm o \n",
      "N\"|   \"AX:A\"Ao \"X||mN\"NNg\"gNmmX\" m\"N   m\"mG\"g  | |NXNg\"\"|\"\n",
      "mNAm ngA n  Bgm\"An\"mmAGmgNC \" A \"\"\"mm \"CGG \n",
      "\"gM \"mNnDm\"mmgg\"\" \" m\n",
      ":XAA6X\n",
      "mN g\"\"\n",
      "m XE\n",
      "\"n Cn\"G\"gm\"mh n mG\"\"|| n|\"G\"Gmg\" ||  n\"\"\"\"m\" \"gm MG \"\"m\"|A Gm gNtm\"\"gXA:A \"m\"m n nW m\n",
      "mAt\"\"\"AA\"\"\"NN\"|Gm e:Ammnm\" Gg\"N\"GD\" \"\n",
      "X|mAm \"mA mA |\"imG\"mNm\"N\"A\"nA n X\"XmAm Am  |\"\"\"X X N\"gmm \"GG\n",
      " \"  AX\n",
      "m  g \"\" \" | Mm  g\"|gAm  tm\"NDmAG m \"\" |mmG\"G A g\"G \"ngGuN mngg\n",
      "C\"m\"m\"m \"\"m\"\"mDA\"\n",
      "\n",
      "\"noA Gm/ mgm m\"  N:\n",
      "\" \"\"\"\"Nm|Ang\"A\n",
      "gND :\"Gm|n \"\"\"m\"G|\"\"\"aX\"g\"SNDX n\" \" m|\"g GAm|m|\"| gm ngDNA \"\"\" m | n1\" \"  m| X AmG\"\"|n  \"|GAl \"\"n \n",
      " Am\" |  mGT mmGB| n:mg nmGm\" gm    D\"| \"\"nGA\"X\"|\"m    \"mG\"D:\\m|Nmmn\"X\"mXXmgA\"n\" D\"mNm\"m \" Xg  \"\"Ag nGNmm \n",
      "m m\"\"\" \"\"\" XA :F Xg n NA\"ng G \"\"mA A\n",
      "\"NnnAN FM|\"mn\" A\"A\"   X  N|AAMAmX\"\"\"m\n",
      "XmXAX\"\n",
      " nN: ngNtm \"nmX\"XM|oGg AXnA mnNNA g\" m|\n",
      "\"\"  Am nXn A\"Xgm\"XDX\"AAm\"mnmG\"\"m\"3m g A\" XG 7mgn  m|\"m\" Nmm\"m\" \"|XXGNX  NmN\"AAD\"Gm\"DGN|g oXn NE\"mA| \"Gmm\"A \"\n",
      "g GmDN G  C\"|Dm \"|\"\"XX\"g\"n\"NXgm\n",
      "m\"mmmXX mmm\"GgAmAgg\"g\"\"\"\"a\"\"\"G\"m\n",
      " \"mXmA'm\"NGA  \"  g   M \n",
      " |mGG|m\"XA\"n\"\"XNn\"mmX AN|\" XGXN\"Gg \"mN |  G|\n",
      "N\"m\n",
      "\"G\"\"nA A\"mXA      XNmG\"\" A\n",
      "\"m Amnm\n",
      "\" T \"\"gA|\"\"\"\"|d  ANnnnXN m\"\"G:XG\"Xmr \" :\"Xm m  mmD\" gnA\\\"D\"\"N\"E mAmGn mN gA\"N\"mt\" m \" |mG-GX\" G m Ggtm 7 NNXmnD G\"n \"n\"m\"Am:Dm\"A\"\"|Mm   \"m\"n \"\"mXCX  \"  N \"n\" \" gEG/\" \"\"Ng \"\"\"\"\"GnXmg\"\"N mbXAX\"mA\"\n",
      "Mmmm\"\" \"An m\"\"\"| m\"N\" gnXtm h nn|\"gGm\"y|\"A  Gg\"A\n",
      " \n",
      "G\"gA\"mn DDmN\" \"\"  GAA\n",
      "XANXN\"m|\"\"|\"\"X n\"mX\"Gnn NAXg \n",
      "D \"m\"Dnm \"X\n",
      "\"\"m\"Mo\"n \"   X\"nX:y\" \"F  \n",
      "\n",
      "\" G nmAmA\"\"%t mGAH mmh|\" Gn|G\"NNN| n  :A NnGNnnmGA\n",
      "|n mD\"||mA\" G\"mX m g DMn\n",
      "Cmn \"nm AA|XAXA\" GM\"\"  \"m\"\"hg\"Agn  n\n",
      "/mbmgm |m-A\"nm m7m n g\"\"gA \" \"m\" nG \"N\" m X\n",
      "\"t\" AGA|mmgg\"gtGmlm :X\"CXnXX|AX\" g\n",
      "\"\"A-mGn|mMb\"M \"\"| mm\"G\"| B\"ng\"XD\"   M|yn  |n\" A\"  \"X\"\"Xm\"NN \"\"mA \"\"AAA\"M\"\"\"|C m\"\" m\"gAb\"  nGMmXGM  m\"A Gcgm  m n X\"G gD\n",
      "dAAdNm \"m\"   \"gG \"\"\"nM g \"\" \"| |GX\"m: n\" \"\"\"\"D\"m NAGn  GGN\"\"\n",
      "\" GgAnhBn\"\" g\"mD\"m\"X \"\"X:X Gm ngmm\" G\"\"\"\n",
      "\n",
      "\"\"mDm\" \"m\" \"XBEmXX XN\"mX\"|   |g gmN mX  Gm \n"
     ]
    }
   ],
   "source": [
    "# def build_generating \n",
    "\n",
    "def generate_data(epoch='final', header='', max_chars=2048):\n",
    "    \n",
    "    with open(os.path.join(DATA_DIR, 'char_to_idx.json')) as f:\n",
    "        char_to_idx = json.load(f)\n",
    "    vocab_size = len(char_to_idx)\n",
    "    \n",
    "    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "    indexed_data = [char_to_idx[i] for i in header]\n",
    "    \n",
    "#     model = open(os.path.join(MODEL_DIR, 'model.json'), 'r').read()\n",
    "#     model = model_from_json(model)\n",
    "    model = get_model(1, 1, vocab_size)\n",
    "    model.load_weights(os.path.join(MODEL_DIR, f'weights.{epoch}.h5'))\n",
    "    \n",
    "    for i in range(max_chars):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = np.random.randint(vocab_size)\n",
    "        \n",
    "        result = model.predict_on_batch(batch).ravel()\n",
    "        indexed_data.append(np.random.choice(range(vocab_size), p=result))\n",
    "    \n",
    "    return ''.join(idx_to_char[i] for i in indexed_data)\n",
    "\n",
    "print(generate_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFv1G37rn62Q"
   },
   "outputs": [],
   "source": [
    "# np.array([0.1, 0.2, 0.3]).reshape((1,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtRnBSzcn62U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShqNyboen62X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQOSvEUwn62a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8Y59hbtn62d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icYYF23xn62g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEZzu6j_n62i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNS8Ss6Mn62o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4naDb8IVn62r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Music_Generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
